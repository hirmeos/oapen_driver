#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import os
import json
import subprocess
from client import IrusClient
from datetime import datetime


MODES = json.loads(os.getenv('MODES'))
OUTDIR = os.environ['OUTDIR']
CACHEDIR = os.environ['CACHEDIR']
REDO_OUTPUT = os.environ['REDO_OUTPUT'] in (True, 'True', 'true', 1)
IRUS_API_REQUESTOR_ID = os.environ['IRUS_API_REQUESTOR_ID']
IRUS_API_KEY = os.environ['IRUS_API_KEY']


def outstream(filename):
    return open(filename, "w")


def instream(filename):
    return open(filename, "r")


def get_cache_filename(odir, mode, date):
    return "%s/%s_%s.json" % (odir, mode, date)


def get_output_filename(odir, date):
    return "%s/OAPEN_%s.csv" % (odir, date)


def exists_and_not_empty(filename):
    try:
        return os.path.getsize(filename) > 0
    except OSError:
        return False


def generate_dates(date, cutoff_date):
    epoch = datetime.strptime(date, '%Y-%m-%d')
    cutoff = datetime.strptime(cutoff_date, '%Y-%m-%d')

    i = epoch
    while i <= cutoff:
        yield i
        i = next_month(i)


def next_month(date):
    month = date.month % 12 + 1
    year = date.year if date.month < 12 else date.year + 1
    return datetime.strptime('%d-%d-01' % (year, month), '%Y-%m-%d')


def previous_month(date):
    month = date.month - 1 if date.month > 1 else 12
    year = date.year if month < 12 else date.year - 1
    return "%s-%s-%s" % (year, month, "01")


def get_earliest(dates):
    earliest = dates[0]
    for date in dates:
        date_time = datetime.strptime(date, '%Y-%m-%d')
        earliest_time = datetime.strptime(earliest, '%Y-%m-%d')
        if date_time < earliest_time:
            earliest = date
    return earliest


def resolve_cache(output_stream, input_stream, measure, headers):
    add_headers = ['--add-headers'] if headers else []
    cmd = ['./resolve_reports',
           '--measure', measure] + add_headers
    subprocess.call(cmd, stdout=output_stream, stdin=input_stream)


def run():
    api = IrusClient(IRUS_API_REQUESTOR_ID, IRUS_API_KEY)

    # cache IRUS-UK API responses for all MODES
    cutoff_date = previous_month(datetime.now())
    for mode in MODES:
        dates = generate_dates(mode['startDate'], cutoff_date)
        for month in dates:
            date = month.strftime('%Y-%m-%d')
            cache_file = get_cache_filename(CACHEDIR, mode['name'], date)
            if exists_and_not_empty(cache_file):
                continue
            request_date = month.strftime('%Y-%m')
            report = api.item_report(request_date, request_date)
            cache = outstream(cache_file)
            cache.write(json.dumps(report))
            cache.close()

    # now we standarise reports and store them in each output CSV
    earliest_date = get_earliest([m['startDate'] for m in MODES])
    for day in generate_dates(earliest_date, cutoff_date):
        date = day.strftime('%Y-%m-%d')
        out_file = get_output_filename(OUTDIR, date)

        # continue if output file already exists
        if exists_and_not_empty(out_file) and not REDO_OUTPUT:
            continue

        i = 0
        output = outstream(out_file)
        for m in MODES:
            cache_file = get_cache_filename(CACHEDIR, m['name'], date)
            # at this point all *relevant* cache files must exists
            if not exists_and_not_empty(cache_file):
                continue
            inputs = instream(cache_file)
            headers = i == 0  # only include headers in first iteration
            i += 1
            resolve_cache(output, inputs, m['measure'], headers)


if __name__ == '__main__':
    run()
